Yes! You can store the output in a list format, where each entry contains:
1️⃣ Tokens (Words)
2️⃣ Actual Tags (Ground Truth)
3️⃣ Predicted Tags (Model Output)

✅ Storing Output in a List Format
Modify the function to return the output as a list of lists instead of a CSV file:

python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset, tokenizer):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Get actual label indices

    output_list = []  # Store final output in list format

    for i in range(len(dataset)):
        input_ids = dataset[i]["input_ids"].tolist()  # Convert token IDs to tokens
        word_ids = dataset[i]["word_ids"]
        tokens = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)

        sentence_tokens = []
        sentence_true_labels = []
        sentence_pred_labels = []

        previous_word_idx = None
        for j, word_idx in enumerate(word_ids):
            if word_idx is None or word_idx == previous_word_idx:
                continue  # Ignore subwords and padding
            
            sentence_tokens.append(tokens[j])  # Store token
            sentence_true_labels.append(id2label.get(int(labels[i][word_idx]), "O"))  # Actual tag
            sentence_pred_labels.append(id2label.get(int(predictions[i][word_idx]), "O"))  # Predicted tag

            previous_word_idx = word_idx

        # Store as a list: [tokens_list, actual_tags_list, predicted_tags_list]
        output_list.append([sentence_tokens, sentence_true_labels, sentence_pred_labels])

    return output_list
✅ Get Train & Test Predictions in List Format
python
Copy
Edit
train_predictions_list = get_predictions(trainer, dataset_train, tokenizer)
test_predictions_list = get_predictions(trainer, dataset_test, tokenizer)

# Example: Check the first few sentences
print("Train Example:", train_predictions_list[:3])
print("\nTest Example:", test_predictions_list[:3])
📌 Example Output (List Format)
python
Copy
Edit
[
    [
        ['Elon', 'Musk', 'founded', 'SpaceX', 'in', '2002', '.'],  # Tokens
        ['B-PER', 'I-PER', 'O', 'B-ORG', 'O', 'B-DATE', 'O'],  # Actual Tags
        ['B-PER', 'I-PER', 'O', 'B-ORG', 'O', 'B-DATE', 'O']   # Predicted Tags
    ],
    [
        ['Google', 'is', 'a', 'tech', 'company', '.'],
        ['B-ORG', 'O', 'O', 'O', 'O', 'O'],
        ['B-ORG', 'O', 'O', 'O', 'O', 'O']
    ]
]
✅ Each sentence is stored as a nested list with [Tokens, Actual Tags, Predicted Tags].

🚀 Benefits of List Format
✅ Easy to process in Python (can iterate over sentences easily).
✅ No formatting issues like CSV (ensures all words align correctly).
✅ Can be saved in JSON for better readability.
✅ Save Output to JSON (Optional)
If you want to save this structured format to a file:

python
Copy
Edit
import json

with open("train_predictions.json", "w") as f:
    json.dump(train_predictions_list, f, indent=4)

with open("test_predictions.json", "w") as f:
    json.dump(test_predictions_list, f, indent=4)

print("✅ Saved train_predictions.json and test_predictions.json")
This will store the structured format in JSON.

🎯 Summary
You can now store output in a structured list format:
[Tokens, Actual Tags, Predicted Tags]
No subword issues, padding issues, or misaligned tokens.
Optionally save the results in JSON for easy visualization.
Try this and let me know if you need further modifications! 🚀🔥


######

🔍 Issue: Tokens Not Aligning Properly in Final CSV
If your final train/test CSV files have errors such as:
1️⃣ Subwords instead of full words (e.g., "comp", "##uter" instead of "computer")
2️⃣ Mismatched token counts (Extra/missing words)
3️⃣ Too many arguments error

✅ Fix: Properly Align Tokens, Actual Tags, and Predicted Tags
Modify your tokenization & alignment process to handle subwords correctly.

🔹 Step 1: Adjust Tokenization & Alignment
python
Copy
Edit
def tokenize_and_align_labels(sentences, labels, tokenizer):
    tokenized_inputs = tokenizer(
        [[word for word in sentence] for sentence in sentences],
        truncation=True,
        padding=True,
        is_split_into_words=True,
        return_tensors="pt"
    )

    aligned_labels = []
    for i, sentence_labels in enumerate(labels):
        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words
        previous_word_idx = None
        label_ids = []
        
        for word_idx in word_ids:
            if word_idx is None:
                label_ids.append(-100)  # Ignore special tokens
            elif word_idx != previous_word_idx:
                label_ids.append(label2id[sentence_labels[word_idx]])  # Assign correct label
            else:
                label_ids.append(-100)  # Ignore subword tokens
                
            previous_word_idx = word_idx
        
        aligned_labels.append(label_ids)

    tokenized_inputs["labels"] = torch.tensor(aligned_labels)
    return tokenized_inputs
✅ This ensures:

Only the first subword gets a label
Subwords (##word) don’t get duplicate labels
Special tokens ([CLS], [SEP], [PAD]) are ignored
🔹 Step 2: Generate Predictions & Align Them with Tokens
python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset, tokenizer):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Actual label indices

    true_labels_list = []
    predicted_labels_list = []
    tokens_list = []

    for i in range(len(dataset)):
        input_ids = dataset[i]["input_ids"].tolist()  # Convert token IDs to tokens
        word_ids = dataset[i]["word_ids"]
        tokens = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)

        true_labels = []
        predicted_labels = []
        aligned_tokens = []

        previous_word_idx = None
        for j, word_idx in enumerate(word_ids):
            if word_idx is None or word_idx == previous_word_idx:
                continue  # Ignore subwords and padding
            
            aligned_tokens.append(tokens[j])  # Get full words
            true_labels.append(id2label.get(int(labels[i][word_idx]), "O"))  # Assign correct actual label
            predicted_labels.append(id2label.get(int(predictions[i][word_idx]), "O"))  # Assign predicted label

            previous_word_idx = word_idx

        tokens_list.append(aligned_tokens)
        true_labels_list.append(true_labels)
        predicted_labels_list.append(predicted_labels)

    return tokens_list, true_labels_list, predicted_labels_list
✅ This ensures:

Subword tokens don’t appear separately
Actual & predicted labels match words correctly
🔹 Step 3: Save Train & Test Predictions to CSV
python
Copy
Edit
import pandas as pd

def save_predictions(tokens, true_labels, pred_labels, filename):
    flat_tokens = [word for sentence in tokens for word in sentence]
    flat_actual_labels = [label for sentence in true_labels for label in sentence]
    flat_predicted_labels = [label for sentence in pred_labels for label in sentence]

    df = pd.DataFrame({"Token": flat_tokens, "Actual_Tag": flat_actual_labels, "Predicted_Tag": flat_predicted_labels})
    df.to_csv(filename, index=False)
    print(f"✅ Saved: {filename}")

# 🔹 Get predictions for Train & Test
train_tokens, train_true_labels, train_pred_labels = get_predictions(trainer, dataset_train, tokenizer)
test_tokens, test_true_labels, test_pred_labels = get_predictions(trainer, dataset_test, tokenizer)

# 🔹 Save to CSV
save_predictions(train_tokens, train_true_labels, train_pred_labels, "final_train_predictions.csv")
save_predictions(test_tokens, test_true_labels, test_pred_labels, "final_test_predictions.csv")
📂 Expected CSV Output (Correctly Formatted)
Token	Actual_Tag	Predicted_Tag
Apple	B-ORG	B-ORG
is	O	O
a	O	O
company	O	B-ORG
in	O	O
USA	B-LOC	B-LOC
🚀 Final Fixes Summary
✅ Handles subwords correctly → No "comp", "##uter" issues.
✅ Ensures actual vs. predicted labels match words → No missing tokens.
✅ Properly saves train & test files in CSV format
################
To save the final output of train and test datasets with actual vs predicted tags, follow this complete approach. 🚀

📌 Steps
1️⃣ Run Model Predictions on Train & Test Data
2️⃣ Convert Predictions from IDs to Text Labels
3️⃣ Align Words with Actual & Predicted Tags
4️⃣ Save the Results in CSV Format

🔹 Step 1: Generate Predictions
python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Get actual label indices

    true_labels = [[id2label[label] for label in label_seq if label != -100] for label_seq in labels]
    pred_labels = [[id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100] 
                   for pred_seq, label_seq in zip(predictions, labels)]
    
    return true_labels, pred_labels
✅ This removes padding tokens (-100) to keep only relevant words.

🔹 Step 2: Save Predictions in CSV Format
python
Copy
Edit
import pandas as pd

def save_predictions(sentences, true_labels, pred_labels, filename):
    data = []
    for sentence, actual, predicted in zip(sentences, true_labels, pred_labels):
        for word, act_tag, pred_tag in zip(sentence, actual, predicted):
            data.append([word[0], act_tag, pred_tag])

    df = pd.DataFrame(data, columns=["Word", "Actual_Tag", "Predicted_Tag"])
    df.to_csv(filename, index=False)
    print(f"✅ Saved: {filename}")

# 🔹 Predict & Save Train Data
train_true, train_pred = get_predictions(trainer, dataset_train)
save_predictions(dataset_train, train_true, train_pred, "final_train_predictions.csv")

# 🔹 Predict & Save Test Data
test_true, test_pred = get_predictions(trainer, dataset_test)
save_predictions(dataset_test, test_true, test_pred, "final_test_predictions.csv")
✅ The final output files will be saved as: 1️⃣ final_train_predictions.csv
2️⃣ final_test_predictions.csv

📂 Expected CSV Output Format
Word	Actual_Tag	Predicted_Tag
Elon	B-PER	B-PER
Musk	I-PER	I-PER
founded	O	O
SpaceX	B-ORG	B-ORG
in	O	O
2002	B-DATE	B-DATE
✅ Summary
Extracted predictions for Train & Test sets
Converted label IDs into text labels
Saved results in CSV format for easy comparison
Now you can compare Actual vs. Predicted Tags in the final files. 🚀

Would you like to add more insights like error analysis? 🔍
