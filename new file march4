Yes! You can store the output in a list format, where each entry contains:
1ï¸âƒ£ Tokens (Words)
2ï¸âƒ£ Actual Tags (Ground Truth)
3ï¸âƒ£ Predicted Tags (Model Output)

âœ… Storing Output in a List Format
Modify the function to return the output as a list of lists instead of a CSV file:

python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset, tokenizer):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Get actual label indices

    output_list = []  # Store final output in list format

    for i in range(len(dataset)):
        input_ids = dataset[i]["input_ids"].tolist()  # Convert token IDs to tokens
        word_ids = dataset[i]["word_ids"]
        tokens = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)

        sentence_tokens = []
        sentence_true_labels = []
        sentence_pred_labels = []

        previous_word_idx = None
        for j, word_idx in enumerate(word_ids):
            if word_idx is None or word_idx == previous_word_idx:
                continue  # Ignore subwords and padding
            
            sentence_tokens.append(tokens[j])  # Store token
            sentence_true_labels.append(id2label.get(int(labels[i][word_idx]), "O"))  # Actual tag
            sentence_pred_labels.append(id2label.get(int(predictions[i][word_idx]), "O"))  # Predicted tag

            previous_word_idx = word_idx

        # Store as a list: [tokens_list, actual_tags_list, predicted_tags_list]
        output_list.append([sentence_tokens, sentence_true_labels, sentence_pred_labels])

    return output_list
âœ… Get Train & Test Predictions in List Format
python
Copy
Edit
train_predictions_list = get_predictions(trainer, dataset_train, tokenizer)
test_predictions_list = get_predictions(trainer, dataset_test, tokenizer)

# Example: Check the first few sentences
print("Train Example:", train_predictions_list[:3])
print("\nTest Example:", test_predictions_list[:3])
ğŸ“Œ Example Output (List Format)
python
Copy
Edit
[
    [
        ['Elon', 'Musk', 'founded', 'SpaceX', 'in', '2002', '.'],  # Tokens
        ['B-PER', 'I-PER', 'O', 'B-ORG', 'O', 'B-DATE', 'O'],  # Actual Tags
        ['B-PER', 'I-PER', 'O', 'B-ORG', 'O', 'B-DATE', 'O']   # Predicted Tags
    ],
    [
        ['Google', 'is', 'a', 'tech', 'company', '.'],
        ['B-ORG', 'O', 'O', 'O', 'O', 'O'],
        ['B-ORG', 'O', 'O', 'O', 'O', 'O']
    ]
]
âœ… Each sentence is stored as a nested list with [Tokens, Actual Tags, Predicted Tags].

ğŸš€ Benefits of List Format
âœ… Easy to process in Python (can iterate over sentences easily).
âœ… No formatting issues like CSV (ensures all words align correctly).
âœ… Can be saved in JSON for better readability.
âœ… Save Output to JSON (Optional)
If you want to save this structured format to a file:

python
Copy
Edit
import json

with open("train_predictions.json", "w") as f:
    json.dump(train_predictions_list, f, indent=4)

with open("test_predictions.json", "w") as f:
    json.dump(test_predictions_list, f, indent=4)

print("âœ… Saved train_predictions.json and test_predictions.json")
This will store the structured format in JSON.

ğŸ¯ Summary
You can now store output in a structured list format:
[Tokens, Actual Tags, Predicted Tags]
No subword issues, padding issues, or misaligned tokens.
Optionally save the results in JSON for easy visualization.
Try this and let me know if you need further modifications! ğŸš€ğŸ”¥


######

ğŸ” Issue: Tokens Not Aligning Properly in Final CSV
If your final train/test CSV files have errors such as:
1ï¸âƒ£ Subwords instead of full words (e.g., "comp", "##uter" instead of "computer")
2ï¸âƒ£ Mismatched token counts (Extra/missing words)
3ï¸âƒ£ Too many arguments error

âœ… Fix: Properly Align Tokens, Actual Tags, and Predicted Tags
Modify your tokenization & alignment process to handle subwords correctly.

ğŸ”¹ Step 1: Adjust Tokenization & Alignment
python
Copy
Edit
def tokenize_and_align_labels(sentences, labels, tokenizer):
    tokenized_inputs = tokenizer(
        [[word for word in sentence] for sentence in sentences],
        truncation=True,
        padding=True,
        is_split_into_words=True,
        return_tensors="pt"
    )

    aligned_labels = []
    for i, sentence_labels in enumerate(labels):
        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to words
        previous_word_idx = None
        label_ids = []
        
        for word_idx in word_ids:
            if word_idx is None:
                label_ids.append(-100)  # Ignore special tokens
            elif word_idx != previous_word_idx:
                label_ids.append(label2id[sentence_labels[word_idx]])  # Assign correct label
            else:
                label_ids.append(-100)  # Ignore subword tokens
                
            previous_word_idx = word_idx
        
        aligned_labels.append(label_ids)

    tokenized_inputs["labels"] = torch.tensor(aligned_labels)
    return tokenized_inputs
âœ… This ensures:

Only the first subword gets a label
Subwords (##word) donâ€™t get duplicate labels
Special tokens ([CLS], [SEP], [PAD]) are ignored
ğŸ”¹ Step 2: Generate Predictions & Align Them with Tokens
python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset, tokenizer):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Actual label indices

    true_labels_list = []
    predicted_labels_list = []
    tokens_list = []

    for i in range(len(dataset)):
        input_ids = dataset[i]["input_ids"].tolist()  # Convert token IDs to tokens
        word_ids = dataset[i]["word_ids"]
        tokens = tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=True)

        true_labels = []
        predicted_labels = []
        aligned_tokens = []

        previous_word_idx = None
        for j, word_idx in enumerate(word_ids):
            if word_idx is None or word_idx == previous_word_idx:
                continue  # Ignore subwords and padding
            
            aligned_tokens.append(tokens[j])  # Get full words
            true_labels.append(id2label.get(int(labels[i][word_idx]), "O"))  # Assign correct actual label
            predicted_labels.append(id2label.get(int(predictions[i][word_idx]), "O"))  # Assign predicted label

            previous_word_idx = word_idx

        tokens_list.append(aligned_tokens)
        true_labels_list.append(true_labels)
        predicted_labels_list.append(predicted_labels)

    return tokens_list, true_labels_list, predicted_labels_list
âœ… This ensures:

Subword tokens donâ€™t appear separately
Actual & predicted labels match words correctly
ğŸ”¹ Step 3: Save Train & Test Predictions to CSV
python
Copy
Edit
import pandas as pd

def save_predictions(tokens, true_labels, pred_labels, filename):
    flat_tokens = [word for sentence in tokens for word in sentence]
    flat_actual_labels = [label for sentence in true_labels for label in sentence]
    flat_predicted_labels = [label for sentence in pred_labels for label in sentence]

    df = pd.DataFrame({"Token": flat_tokens, "Actual_Tag": flat_actual_labels, "Predicted_Tag": flat_predicted_labels})
    df.to_csv(filename, index=False)
    print(f"âœ… Saved: {filename}")

# ğŸ”¹ Get predictions for Train & Test
train_tokens, train_true_labels, train_pred_labels = get_predictions(trainer, dataset_train, tokenizer)
test_tokens, test_true_labels, test_pred_labels = get_predictions(trainer, dataset_test, tokenizer)

# ğŸ”¹ Save to CSV
save_predictions(train_tokens, train_true_labels, train_pred_labels, "final_train_predictions.csv")
save_predictions(test_tokens, test_true_labels, test_pred_labels, "final_test_predictions.csv")
ğŸ“‚ Expected CSV Output (Correctly Formatted)
Token	Actual_Tag	Predicted_Tag
Apple	B-ORG	B-ORG
is	O	O
a	O	O
company	O	B-ORG
in	O	O
USA	B-LOC	B-LOC
ğŸš€ Final Fixes Summary
âœ… Handles subwords correctly â†’ No "comp", "##uter" issues.
âœ… Ensures actual vs. predicted labels match words â†’ No missing tokens.
âœ… Properly saves train & test files in CSV format
################
To save the final output of train and test datasets with actual vs predicted tags, follow this complete approach. ğŸš€

ğŸ“Œ Steps
1ï¸âƒ£ Run Model Predictions on Train & Test Data
2ï¸âƒ£ Convert Predictions from IDs to Text Labels
3ï¸âƒ£ Align Words with Actual & Predicted Tags
4ï¸âƒ£ Save the Results in CSV Format

ğŸ”¹ Step 1: Generate Predictions
python
Copy
Edit
import numpy as np

def get_predictions(trainer, dataset):
    predictions_output = trainer.predict(dataset)
    predictions = np.argmax(predictions_output.predictions, axis=2)  # Convert logits to label indices
    labels = predictions_output.label_ids  # Get actual label indices

    true_labels = [[id2label[label] for label in label_seq if label != -100] for label_seq in labels]
    pred_labels = [[id2label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100] 
                   for pred_seq, label_seq in zip(predictions, labels)]
    
    return true_labels, pred_labels
âœ… This removes padding tokens (-100) to keep only relevant words.

ğŸ”¹ Step 2: Save Predictions in CSV Format
python
Copy
Edit
import pandas as pd

def save_predictions(sentences, true_labels, pred_labels, filename):
    data = []
    for sentence, actual, predicted in zip(sentences, true_labels, pred_labels):
        for word, act_tag, pred_tag in zip(sentence, actual, predicted):
            data.append([word[0], act_tag, pred_tag])

    df = pd.DataFrame(data, columns=["Word", "Actual_Tag", "Predicted_Tag"])
    df.to_csv(filename, index=False)
    print(f"âœ… Saved: {filename}")

# ğŸ”¹ Predict & Save Train Data
train_true, train_pred = get_predictions(trainer, dataset_train)
save_predictions(dataset_train, train_true, train_pred, "final_train_predictions.csv")

# ğŸ”¹ Predict & Save Test Data
test_true, test_pred = get_predictions(trainer, dataset_test)
save_predictions(dataset_test, test_true, test_pred, "final_test_predictions.csv")
âœ… The final output files will be saved as: 1ï¸âƒ£ final_train_predictions.csv
2ï¸âƒ£ final_test_predictions.csv

ğŸ“‚ Expected CSV Output Format
Word	Actual_Tag	Predicted_Tag
Elon	B-PER	B-PER
Musk	I-PER	I-PER
founded	O	O
SpaceX	B-ORG	B-ORG
in	O	O
2002	B-DATE	B-DATE
âœ… Summary
Extracted predictions for Train & Test sets
Converted label IDs into text labels
Saved results in CSV format for easy comparison
Now you can compare Actual vs. Predicted Tags in the final files. ğŸš€

Would you like to add more insights like error analysis? ğŸ”
